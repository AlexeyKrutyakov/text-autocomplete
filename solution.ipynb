{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade2f2a5",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6cfb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programming\\text-autocomplete\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from src.lstm_model import LSTMModel\n",
    "from src.eval_lstm import evaluate_lstm\n",
    "from src.lstm_train import train_lstm\n",
    "from src.eval_transformer_pipeline import evaluate_transformer\n",
    "from src.data_utils import (\n",
    "  load_texts,\n",
    "  clean_text,\n",
    "  save_texts,\n",
    "  tokenize,\n",
    "  save_tokenized,\n",
    "  load_tokenized,\n",
    "  is_ascii,\n",
    "  filter_by_length,\n",
    "  train_val_test_split,\n",
    "  prepare_tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721be24a",
   "metadata": {},
   "source": [
    "#### Create global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77cbe181",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "TOKENIZE_MODEL = 'gpt2'\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "PRETRAINED_TRANSFORMER = 'distilgpt2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad7038",
   "metadata": {},
   "source": [
    "#### Clean dataset and save to file or load cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae7cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = 'data/dataset_processed.txt'\n",
    "\n",
    "if os.path.exists(processed_path):\n",
    "  cleaned_ascii_texts = load_texts(processed_path)\n",
    "else:\n",
    "  texts = load_texts('data/tweets.txt')\n",
    "  cleaned_texts = [clean_text(t) for t in texts]\n",
    "  cleaned_ascii_texts = [t for t in cleaned_texts if is_ascii(t)]\n",
    "\n",
    "  save_texts(cleaned_ascii_texts, 'data/dataset_processed.txt')\n",
    "  print(f'Dataset cleaned and saved: {len(cleaned_ascii_texts)} lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8a8f9",
   "metadata": {},
   "source": [
    "#### Tokenize cleaned dataset if not exists and analyze lengths of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fbe674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized data: 1596158\n"
     ]
    }
   ],
   "source": [
    "tokenized_path = 'data/dataset_tokenized.json'\n",
    "\n",
    "if not os.path.exists(tokenized_path):\n",
    "  tokenized = tokenize(cleaned_ascii_texts, model_name=TOKENIZE_MODEL)\n",
    "  \n",
    "  save_tokenized(tokenized, tokenized_path)\n",
    "  \n",
    "  print(f'Tokenized and saved: {len(tokenized)} samples')\n",
    "\n",
    "  # analyze lengths of samples\n",
    "  lengths = [len(t) for t in tokenized]\n",
    "\n",
    "  print(f'Min: {min(lengths)}, Max: {max(lengths)}, Mean: {np.mean(lengths):.2f}')\n",
    "  for p in [50, 75, 90, 95, 99]:\n",
    "    print(f'P{p}: {int(np.percentile(lengths, p))}')\n",
    "else:\n",
    "  tokenized = load_tokenized(tokenized_path)\n",
    "  print(f'Loaded tokenized data: {len(tokenized)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2384af5",
   "metadata": {},
   "source": [
    "#### Split for train, val, test or load if exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ca349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded from cache:\n",
      "Train: 1195832, Val: 149479, Test: 149480\n"
     ]
    }
   ],
   "source": [
    "train_path = 'data/train.pt'\n",
    "val_path = 'data/val.pt'\n",
    "test_path = 'data/test.pt'\n",
    "\n",
    "if all(os.path.exists(p) for p in [train_path, val_path, test_path]):\n",
    "  train = torch.load(train_path)\n",
    "  val = torch.load(val_path)\n",
    "  test = torch.load(test_path)\n",
    "\n",
    "  print('Datasets loaded from cache:')\n",
    "  print(f\"Train: {len(train['x'])}, Val: {len(val['x'])}, Test: {len(test['x'])}\")\n",
    "else:\n",
    "  filtered = filter_by_length(tokenized=tokenized, min_length=5)\n",
    "  print(f'After filter: {len(filtered)} (length > 5 tokens)')\n",
    "\n",
    "  train_tokenized, val_tokenized, test_tokenized = train_val_test_split(data=filtered, train_ratio=0.8, val_ratio=0.1, seed=42)\n",
    "  print(f'Split - Train: {len(train_tokenized)}, Val: {len(val_tokenized)}, Test: {len(test_tokenized)}')\n",
    "\n",
    "  train_x, train_y = prepare_tensors(train_tokenized, max_length=MAX_LENGTH)\n",
    "  val_x, val_y = prepare_tensors(val_tokenized, max_length=MAX_LENGTH)\n",
    "  test_x, test_y = prepare_tensors(test_tokenized, max_length=MAX_LENGTH)\n",
    "\n",
    "  train = {'x': train_x, 'y': train_y}\n",
    "  val = {'x': val_x, 'y': val_y}\n",
    "  test = {'x': test_x, 'y': test_y}\n",
    "\n",
    "  torch.save(train, train_path)\n",
    "  torch.save(val, val_path)\n",
    "  torch.save(test, test_path)\n",
    "  \n",
    "  print(f\"Saved:\\nTrain: {len(train['x'])}, Val: {len(val['x'])}, Test: {len(test['x'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ade334",
   "metadata": {},
   "source": [
    "#### Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bafa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train['x'], train['y'])\n",
    "val_dataset = TensorDataset(val['x'], val['y'])\n",
    "test_dataset = TensorDataset(test['x'], test['y'])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=True,\n",
    "  num_workers=4,\n",
    "  pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "  val_dataset,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=4,\n",
    "  pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb716978",
   "metadata": {},
   "source": [
    "#### Check batch shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2022f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1195832, Val: 149479, Test: 149480\n",
      "Batch shapes — X: torch.Size([128, 39]), Y: torch.Size([128, 39])\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(f\"Batch shapes — X: {x_batch.shape}, Y: {y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319f267",
   "metadata": {},
   "source": [
    "#### Device setup, create tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04fb6229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(50257, 128)\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZE_MODEL)\n",
    "\n",
    "model = LSTMModel(\n",
    "  vocab_size=tokenizer.vocab_size,\n",
    "  hidden_dim=128,\n",
    "  num_layers=2,\n",
    "  dropout=0.2\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aacddb6",
   "metadata": {},
   "source": [
    "#### Check model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f778f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 13,180,241\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055c5ef",
   "metadata": {},
   "source": [
    "#### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab049dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f5e352",
   "metadata": {},
   "source": [
    "#### Load original tokenized texts for ROUGE evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93514795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val texts for ROUGE: 159616\n"
     ]
    }
   ],
   "source": [
    "_, val_texts, _ = train_val_test_split(tokenized, train_ratio=0.8, val_ratio=0.1, seed=42)\n",
    "print(f'Val texts for ROUGE: {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4a9f4",
   "metadata": {},
   "source": [
    "#### Training loop (for VPS) uses before creating ./src/lstm_train (!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b467e",
   "metadata": {},
   "source": [
    "##### Оставил ячейку, как доказательство обучения на VPS (не запускать повторно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc816b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Batch 500/9343 | Loss: 6.8756 | Time: 49.1s\n",
      "Epoch 1 | Batch 1000/9343 | Loss: 6.2459 | Time: 98.3s\n",
      "Epoch 1 | Batch 1500/9343 | Loss: 5.9440 | Time: 148.1s\n",
      "Epoch 1 | Batch 2000/9343 | Loss: 5.6597 | Time: 198.1s\n",
      "Epoch 1 | Batch 2500/9343 | Loss: 5.7703 | Time: 248.1s\n",
      "Epoch 1 | Batch 3000/9343 | Loss: 5.4670 | Time: 298.2s\n",
      "Epoch 1 | Batch 3500/9343 | Loss: 5.4757 | Time: 348.5s\n",
      "Epoch 1 | Batch 4000/9343 | Loss: 5.5342 | Time: 398.8s\n",
      "Epoch 1 | Batch 4500/9343 | Loss: 5.4333 | Time: 449.1s\n",
      "Epoch 1 | Batch 5000/9343 | Loss: 5.3430 | Time: 499.5s\n",
      "Epoch 1 | Batch 5500/9343 | Loss: 5.3535 | Time: 549.9s\n",
      "Epoch 1 | Batch 6000/9343 | Loss: 5.3936 | Time: 600.2s\n",
      "Epoch 1 | Batch 6500/9343 | Loss: 5.2109 | Time: 650.6s\n",
      "Epoch 1 | Batch 7000/9343 | Loss: 5.3811 | Time: 701.1s\n",
      "Epoch 1 | Batch 7500/9343 | Loss: 5.2598 | Time: 751.5s\n",
      "Epoch 1 | Batch 8000/9343 | Loss: 5.1361 | Time: 801.8s\n",
      "Epoch 1 | Batch 8500/9343 | Loss: 5.3213 | Time: 852.2s\n",
      "Epoch 1 | Batch 9000/9343 | Loss: 5.0904 | Time: 902.6s\n",
      "Epoch 1/5 | Train loss: 5.585042157980049 | Val loss: 5.081881855448631\n",
      "Epoch 2 | Batch 500/9343 | Loss: 5.1611 | Time: 50.4s\n",
      "Epoch 2 | Batch 1000/9343 | Loss: 5.2304 | Time: 100.8s\n",
      "Epoch 2 | Batch 1500/9343 | Loss: 5.2332 | Time: 151.2s\n",
      "Epoch 2 | Batch 2000/9343 | Loss: 5.1089 | Time: 201.6s\n",
      "Epoch 2 | Batch 2500/9343 | Loss: 5.1183 | Time: 252.0s\n",
      "Epoch 2 | Batch 3000/9343 | Loss: 5.1450 | Time: 302.4s\n",
      "Epoch 2 | Batch 3500/9343 | Loss: 5.1306 | Time: 352.7s\n",
      "Epoch 2 | Batch 4000/9343 | Loss: 5.2518 | Time: 403.0s\n",
      "Epoch 2 | Batch 4500/9343 | Loss: 5.1897 | Time: 453.5s\n",
      "Epoch 2 | Batch 5000/9343 | Loss: 5.0999 | Time: 504.0s\n",
      "Epoch 2 | Batch 5500/9343 | Loss: 5.0025 | Time: 554.4s\n",
      "Epoch 2 | Batch 6000/9343 | Loss: 5.0842 | Time: 604.7s\n",
      "Epoch 2 | Batch 6500/9343 | Loss: 5.0352 | Time: 655.0s\n",
      "Epoch 2 | Batch 7000/9343 | Loss: 5.1984 | Time: 705.3s\n",
      "Epoch 2 | Batch 7500/9343 | Loss: 5.1587 | Time: 755.6s\n",
      "Epoch 2 | Batch 8000/9343 | Loss: 5.1977 | Time: 805.8s\n",
      "Epoch 2 | Batch 8500/9343 | Loss: 5.0003 | Time: 856.2s\n",
      "Epoch 2 | Batch 9000/9343 | Loss: 5.0453 | Time: 906.6s\n",
      "Epoch 2/5 | Train loss: 5.149535594935286 | Val loss: 4.961308993705331\n",
      "Epoch 3 | Batch 500/9343 | Loss: 5.1514 | Time: 50.4s\n",
      "Epoch 3 | Batch 1000/9343 | Loss: 4.9492 | Time: 100.8s\n",
      "Epoch 3 | Batch 1500/9343 | Loss: 5.0068 | Time: 151.2s\n",
      "Epoch 3 | Batch 2000/9343 | Loss: 5.0562 | Time: 201.6s\n",
      "Epoch 3 | Batch 2500/9343 | Loss: 5.1979 | Time: 251.9s\n",
      "Epoch 3 | Batch 3000/9343 | Loss: 4.9944 | Time: 302.2s\n",
      "Epoch 3 | Batch 3500/9343 | Loss: 5.0037 | Time: 352.6s\n",
      "Epoch 3 | Batch 4000/9343 | Loss: 5.0798 | Time: 402.9s\n",
      "Epoch 3 | Batch 4500/9343 | Loss: 5.0761 | Time: 453.1s\n",
      "Epoch 3 | Batch 5000/9343 | Loss: 5.0563 | Time: 503.5s\n",
      "Epoch 3 | Batch 5500/9343 | Loss: 5.1616 | Time: 553.9s\n",
      "Epoch 3 | Batch 6000/9343 | Loss: 4.9611 | Time: 604.3s\n",
      "Epoch 3 | Batch 6500/9343 | Loss: 5.1895 | Time: 654.6s\n",
      "Epoch 3 | Batch 7000/9343 | Loss: 5.0245 | Time: 704.9s\n",
      "Epoch 3 | Batch 7500/9343 | Loss: 5.1824 | Time: 755.4s\n",
      "Epoch 3 | Batch 8000/9343 | Loss: 4.8311 | Time: 805.7s\n",
      "Epoch 3 | Batch 8500/9343 | Loss: 5.1893 | Time: 856.1s\n",
      "Epoch 3 | Batch 9000/9343 | Loss: 5.0697 | Time: 906.5s\n",
      "Epoch 3/5 | Train loss: 5.067433121193403 | Val loss: 4.910869507348701\n",
      "Epoch 4 | Batch 500/9343 | Loss: 5.0869 | Time: 50.4s\n",
      "Epoch 4 | Batch 1000/9343 | Loss: 4.9748 | Time: 100.7s\n",
      "Epoch 4 | Batch 1500/9343 | Loss: 4.9643 | Time: 151.1s\n",
      "Epoch 4 | Batch 2000/9343 | Loss: 5.1237 | Time: 201.4s\n",
      "Epoch 4 | Batch 2500/9343 | Loss: 5.1109 | Time: 251.7s\n",
      "Epoch 4 | Batch 3000/9343 | Loss: 4.9791 | Time: 302.1s\n",
      "Epoch 4 | Batch 3500/9343 | Loss: 5.0553 | Time: 352.5s\n",
      "Epoch 4 | Batch 4000/9343 | Loss: 4.9464 | Time: 402.8s\n",
      "Epoch 4 | Batch 4500/9343 | Loss: 5.1035 | Time: 453.3s\n",
      "Epoch 4 | Batch 5000/9343 | Loss: 5.2559 | Time: 503.6s\n",
      "Epoch 4 | Batch 5500/9343 | Loss: 4.7958 | Time: 553.9s\n",
      "Epoch 4 | Batch 6000/9343 | Loss: 4.9221 | Time: 604.2s\n",
      "Epoch 4 | Batch 6500/9343 | Loss: 4.9403 | Time: 654.6s\n",
      "Epoch 4 | Batch 7000/9343 | Loss: 4.8442 | Time: 705.0s\n",
      "Epoch 4 | Batch 7500/9343 | Loss: 5.0817 | Time: 755.4s\n",
      "Epoch 4 | Batch 8000/9343 | Loss: 5.1514 | Time: 805.7s\n",
      "Epoch 4 | Batch 8500/9343 | Loss: 4.8555 | Time: 856.0s\n",
      "Epoch 4 | Batch 9000/9343 | Loss: 5.1177 | Time: 906.5s\n",
      "Epoch 4/5 | Train loss: 5.02550145725641 | Val loss: 4.885281533411105\n",
      "Epoch 5 | Batch 500/9343 | Loss: 4.9306 | Time: 50.5s\n",
      "Epoch 5 | Batch 1000/9343 | Loss: 5.0026 | Time: 100.9s\n",
      "Epoch 5 | Batch 1500/9343 | Loss: 5.0429 | Time: 151.3s\n",
      "Epoch 5 | Batch 2000/9343 | Loss: 5.1730 | Time: 201.6s\n",
      "Epoch 5 | Batch 2500/9343 | Loss: 5.0335 | Time: 251.9s\n",
      "Epoch 5 | Batch 3000/9343 | Loss: 4.8992 | Time: 302.3s\n",
      "Epoch 5 | Batch 3500/9343 | Loss: 5.1559 | Time: 352.7s\n",
      "Epoch 5 | Batch 4000/9343 | Loss: 5.0232 | Time: 403.1s\n",
      "Epoch 5 | Batch 4500/9343 | Loss: 5.0429 | Time: 453.5s\n",
      "Epoch 5 | Batch 5000/9343 | Loss: 5.0618 | Time: 503.8s\n",
      "Epoch 5 | Batch 5500/9343 | Loss: 5.0685 | Time: 554.1s\n",
      "Epoch 5 | Batch 6000/9343 | Loss: 4.9270 | Time: 604.4s\n",
      "Epoch 5 | Batch 6500/9343 | Loss: 5.1505 | Time: 654.7s\n",
      "Epoch 5 | Batch 7000/9343 | Loss: 4.9515 | Time: 705.1s\n",
      "Epoch 5 | Batch 7500/9343 | Loss: 5.1986 | Time: 755.4s\n",
      "Epoch 5 | Batch 8000/9343 | Loss: 5.0990 | Time: 805.7s\n",
      "Epoch 5 | Batch 8500/9343 | Loss: 5.0452 | Time: 856.2s\n",
      "Epoch 5 | Batch 9000/9343 | Loss: 4.8954 | Time: 906.6s\n",
      "Epoch 5/5 | Train loss: 4.998750683940555 | Val loss: 4.86102548935642\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "  model.train()\n",
    "  total_loss = 0.0\n",
    "  t0 = time.time()\n",
    "\n",
    "  for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(x_batch)\n",
    "\n",
    "    loss = criterion(logits.view(-1, logits.size(-1)), y_batch.view(-1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    if (i + 1) % 500 == 0:\n",
    "      elapsed = time.time() - t0\n",
    "      print(f'Epoch {epoch + 1} | Batch {i + 1}/{len(train_loader)} | Loss: {loss.item():.4f} | Time: {elapsed:.1f}s')\n",
    "\n",
    "  total_loss /= len(train_loader)\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for x_batch, y_batch in val_loader:\n",
    "      x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "      logits = model(x_batch)\n",
    "      loss = criterion(logits.view(-1, logits.size(-1)), y_batch.view(-1))\n",
    "      val_loss += loss.item()\n",
    "\n",
    "  val_loss /= len(val_loader)\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{NUM_EPOCHS} | Train loss: {total_loss} | Val loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3aaaaa",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe828486",
   "metadata": {},
   "source": [
    "##### Для последующих запусков обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_lstm(\n",
    "  model=model,\n",
    "  train_loader=train_loader,\n",
    "  val_loader=val_loader,\n",
    "  tokenizer=tokenizer,\n",
    "  val_texts=val_texts,\n",
    "  device=device,\n",
    "  num_epochs=NUM_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4306b4",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8166bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'models/lstm_model.pt')\n",
    "print('Model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf6b92",
   "metadata": {},
   "source": [
    "#### Load trained LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33cb3c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM trained model loaded\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(\n",
    "  vocab_size=tokenizer.vocab_size,\n",
    "  hidden_dim=128,\n",
    "  num_layers=2,\n",
    "  dropout=0.2\n",
    ")\n",
    "model.load_state_dict(torch.load('models/lstm_model.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print('LSTM trained model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3793731",
   "metadata": {},
   "source": [
    "#### Evaluate LSTM trained model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46786596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LSTM: 100%|██████████| 200/200 [00:00<00:00, 238.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM ROUGE-1: 0.0879\n",
      "LSTM ROUGE-2: 0.0172\n",
      "LSTM ROUGE-L: 0.0873\n",
      "\n",
      "Examples:\n",
      "\n",
      "--- Example 1 ---\n",
      "Input: yay! someone got\n",
      "Target:  it!\n",
      "Prediction:  a new\n",
      "\n",
      "--- Example 2 ---\n",
      "Input: we were forced to turn it down! my friends mom\n",
      "Target:  is a spoil sport\n",
      "Prediction:  is going to be\n",
      "\n",
      "--- Example 3 ---\n",
      "Input: being honest, i'm exhausted my brain is dry and i miss my\n",
      "Target:  fiance. just being honest\n",
      "Prediction:  friends. i'm so\n",
      "\n",
      "--- Example 4 ---\n",
      "Input: on my way to race hector hes gonna lose! and also going to the\n",
      "Target:  batting cages im gonna lose!\n",
      "Prediction:  airport. i'm so excited\n",
      "\n",
      "--- Example 5 ---\n",
      "Input: has cut all her\n",
      "Target:  nails off\n",
      "Prediction:  hair.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_results = evaluate_lstm(\n",
    "  model=model,\n",
    "  tokenizer=tokenizer,\n",
    "  texts=val_texts,\n",
    "  device=device,\n",
    "  max_samples=200\n",
    ")\n",
    "\n",
    "print(f'LSTM ROUGE-1: {lstm_results[\"rouge1\"]:.4f}')\n",
    "print(f'LSTM ROUGE-2: {lstm_results[\"rouge2\"]:.4f}')\n",
    "print(f'LSTM ROUGE-L: {lstm_results[\"rougeL\"]:.4f}')\n",
    "\n",
    "print('\\nExamples:')\n",
    "for i, ex in enumerate(lstm_results['examples']):\n",
    "  print(f'\\n--- Example {i + 1} ---')\n",
    "  print(f'Input: {ex[\"input\"]}')\n",
    "  print(f'Target: {ex[\"target\"]}')\n",
    "  print(f'Prediction: {ex[\"prediction\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd6b2b",
   "metadata": {},
   "source": [
    "#### Load pretrained transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0a3af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "distilgpt2 parameters: 81,912,576\n"
     ]
    }
   ],
   "source": [
    "gpt_tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_TRANSFORMER)\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(PRETRAINED_TRANSFORMER)\n",
    "gpt_model.to(device)\n",
    "gpt_model.eval()\n",
    "\n",
    "print(f'Device: {device}')\n",
    "print(f'{PRETRAINED_TRANSFORMER} parameters: {sum(p.numel() for p in gpt_model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5da05",
   "metadata": {},
   "source": [
    "#### Evaluate pretrained transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26bf4ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Transformer: 100%|██████████| 200/200 [00:07<00:00, 25.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilgpt2 ROUGE-1: 0.0616\n",
      "distilgpt2 ROUGE-2: 0.0092\n",
      "distilgpt2 ROUGE-L: 0.0616\n",
      "\n",
      "Examples:\n",
      "\n",
      "--- Example 1 ---\n",
      "Input: yay! someone got\n",
      "Target:  it!\n",
      "Prediction:  a new\n",
      "\n",
      "--- Example 2 ---\n",
      "Input: we were forced to turn it down! my friends mom\n",
      "Target:  is a spoil sport\n",
      "Prediction:  is going to be\n",
      "\n",
      "--- Example 3 ---\n",
      "Input: being honest, i'm exhausted my brain is dry and i miss my\n",
      "Target:  fiance. just being honest\n",
      "Prediction:  friends. i'm so\n",
      "\n",
      "--- Example 4 ---\n",
      "Input: on my way to race hector hes gonna lose! and also going to the\n",
      "Target:  batting cages im gonna lose!\n",
      "Prediction:  airport. i'm so excited\n",
      "\n",
      "--- Example 5 ---\n",
      "Input: has cut all her\n",
      "Target:  nails off\n",
      "Prediction:  hair.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_results = evaluate_transformer(\n",
    "  model=gpt_model,\n",
    "  tokenizer=gpt_tokenizer,\n",
    "  texts=val_texts,\n",
    "  device=device,\n",
    "  max_samples=200,\n",
    "  do_sample=False\n",
    ")\n",
    "\n",
    "print(f'{PRETRAINED_TRANSFORMER} ROUGE-1: {gpt_results[\"rouge1\"]:.4f}')\n",
    "print(f'{PRETRAINED_TRANSFORMER} ROUGE-2: {gpt_results[\"rouge2\"]:.4f}')\n",
    "print(f'{PRETRAINED_TRANSFORMER} ROUGE-L: {gpt_results[\"rougeL\"]:.4f}')\n",
    "\n",
    "print('\\nExamples:')\n",
    "for i, ex in enumerate(lstm_results['examples']):\n",
    "  print(f'\\n--- Example {i + 1} ---')\n",
    "  print(f'Input: {ex[\"input\"]}')\n",
    "  print(f'Target: {ex[\"target\"]}')\n",
    "  print(f'Prediction: {ex[\"prediction\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3602c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10cd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
